---
published: true
author: acarr
layout: default_post
title: 'White Paper: Optimising Data Lakes for Financial Services'
---
## Four Key Questions and a Word of Warning

Data lakes?  Most financial service organisations either have one or are considering one.

They can lead to cost savings or revenue generation when they are used correctly.
  
<a href="http://bit.ly/data-lakes-SL"><img src="{{ site.baseurl }}/acarr/assets/image1.png" /></a>

But they are a minefield, so many organisations struggle with the design and implementation and it’s so easy to get key architectural decisions wrong early on which can hamper the effectiveness of the data lake, and often negative any potential benefits.  Do you dump all your raw data in, do you transform before you dump in?  How do you control access on the data lake to prevent breaking Chinese walls?  Do you stream the data in or insert it via batch processing?  With so many choices it is easy to see why so many organisations have challenges with their initial data lake implementation.

Using knowledge gained from the experience of many implementations of data lakes, the white paper explains key considerations and a warning to help guide a new data lake or optimise a current data lake to fulfil it’s requirements.

[Download the white paper now](http://bit.ly/data-lakes-SL). Prefer to receive a printed version through the post? [Email myself](mailto:andrew.carr@scottlogic.com) and I'll send you a copy.
